<!DOCTYPE html>
<html>

<head>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Julius+Sans+One&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>Welcome</title>
</head>

<body>
    <div id="head">
        <h3 class="welcome">
            To lovely gentlemen
        </h3>
    </div>
    <div class="button">
        <a href="register.html">
            <button class="reg">Sign Up</button>
        </a>
        <a href="login.html">
            <button class="log">Sign in</button>
        </a>
    </div>

    <pre>
    <code style="color: teal;">
        ###################
        Work IV
        ###################

        import numpy as np
        import cv2
        from gpiozero import RGBLED
        
        led = RGBLED(2,3,4)
        
        COLOR_ROWS = 80
        COLOR_COLS = 250
        capture = cv2.VideoCapture(0)
        capture.set(3,1280)
        capture.set(4,720)
        if not capture.isOpened() :
                raise RuntimeError('Error opening VideoCapture.')
        
        colorArray = np.zeros((COLOR_ROWS,COLOR_COLS,3),dtype=np.uint8)
        while True:
                grabbed, frame = capture.read()
                height, width = frame.shape[:2]
                cv2.circle(frame,(int(width/2),int(height/2)),20,(0,0,255),0)
        
                if not grabbed :
                        break
        
                keyVal = cv2.waitKey(1) % 0xFF
                if keyVal == ord('q'):
                        break
        
                shot = frame.copy()
        
                colorArray[:] = shot[int(height/2),int(width/2),:]
                rgb = shot[int(height/2),int(width/2),[2,1,0]]
        
                luminance = 1 - (0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]) / 255
                if luminance < 0.5 :
                        textColor = [0,0,0]
                else :
                        textColor = [255,255,255]
                print(list(rgb))
        
                rgb = list(rgb)
                led.color = (rgb[0]/255,rgb[1]/255,rgb[2]/255)
                #print('Red : '+str(round(rgb[0]/2.55,2)),'Green : '+str(round(rgb[1]/2.55,2)),'Blue : '+str(round(rgb[2]/2.55,2)))
        
                cv2.putText(colorArray,str(rgb),(20,COLOR_ROWS-20),fontFace = cv2.FONT_HERSHEY_SIMPLEX,fontScale=0.8,color=textColor)
                cv2.imshow('Color',colorArray)
        
        capture.release()
        cv2.destroyAllWindows()</code></pre>

    <pre>
            <code style="color: teal;">
                ###################
                Work III
                ###################
                from gpiozero import RGBLED
                from time import sleep
                led = RGBLED(2,3,4)

                while True :
                    rgb = list(map(int,input('Please input RGB here >>> ').split(' ')))
                    led.color = (rgb[0]/255,rgb[1]/255,rgb[2]/255)
                    print('Red : '+str(round(rgb[0]/2.55,2)),'Green : '+str(round(rgb[1]/2.55,2)),'Blue : '+str(round(rgb[2]/2.55,2)))
                    sleep(1)
            </code>
        </pre>

    <pre>
        <h2 style="color: green">Click <a style="color: red" href="https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml" target="_">I am virus</a> <<<< goto cascade file then right click "Save As"</h2>
        <code style="color:blue">
        ###################
        13Dec2021 create data
        ###################
        import cv2

        classifier = cv2.CascadeClassifier('Dataset/haarcascade_frontalface_default.xml')

        cap = cv2.VideoCapture(0)
        text = "Dunk"
        while True :
            _ , img = cap.read()
            imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
            detector = classifier.detectMultiScale(imgGray,scaleFactor=1.1,minNeighbors=4)

            if len(detector) > 0 :
                for (x,y,w,h) in detector :
                    face_area = imgGray[y:y+h,x:x+w]
                    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)
                    cv2.putText(img,text,(int(x+(w/2)-(len(text)*8)),y-8),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),2)
                    cv2.imshow('Result',img)

            else :
                cv2.imshow('Result',img)

            if cv2.waitKey(1) & 0xFF == ord('q') :
                break
        </code>
    </pre>

    <pre>
        <code style="color: green;">
            ###################
            test
            ###################
            import cv2

            classifier = cv2.CascadeClassifier('../Dataset/haarcascade_frontalface_default.xml')
            
            
            clf = cv2.face.LBPHFaceRecognizer_create()
            clf.read('classifier.xml')
            
            
            img = cv2.imread('tester2.jpg')
            imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
            detector = classifier.detectMultiScale(imgGray,scaleFactor=1.1,minNeighbors=4)
            
            for (x,y,w,h) in detector :
                face_area = imgGray[y:y+h,x:x+w]
                label , confidence = clf.predict(face_area)
                cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)
                if label == 2:
                    text1 = f'NAME1 {100-confidence:.2f}%'
                    cv2.putText(img,text1,(int(x+(w/2)-(len(text1)*8)),y-8),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),2)
                if label == 1:
                    text2 = f'NAME2 {100-confidence:.2f}%'
                    cv2.putText(img,text2,(int(x+(w/2)-(len(text2)*8)),y-8),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),2)
            
                cv2.imshow('Result',img)
            
            if cv2.waitKey(0) & 0xFF == ord('q') :
                cv2.destroyAllWindows()  
        </code>
    </pre>
    <pre>
        <code style="color: red;">
            ###################
            train
            ###################
            import numpy as np
            import cv2
            from PIL import Image
            import os

            def train_classifier(data_dir) :
                path = [os.path.join(data_dir,f) for f in os.listdir(data_dir)]
                faces = []
                identifiers = []

                for image in path :
                    img = Image.open(image).convert('L')
                    imageNp = np.array(img,'uint8')
                    identifier = int(os.path.split(image)[1].split('.')[1])
                    faces.append(imageNp)
                    identifiers.append(identifier)

                identifiers = np.array(identifiers)
                clf = cv2.face.LBPHFaceRecognizer_create()
                clf.train(faces,identifiers)
                clf.write('classifier.xml')

            print('-'*5+'Start'+'-'*5)
            train_classifier(('dataset'))
            print('-'*5+'Training Done'+'-'*5)
        </code>
    </pre>
</body>

</html>